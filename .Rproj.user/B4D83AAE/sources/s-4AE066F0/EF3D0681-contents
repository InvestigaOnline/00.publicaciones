---
title: "PLS - MGA HOTELES y AGENCIAS"
author: "Roberto Gil-Saura"
date: "`r Sys.time()`"
editor_options: 
  chunk_output_type: inline
---

NOTA: Incluye constructo de segundo orden

```{=html}
<style type="text/css">
.main-container {
  max-width: 100%;
  margin-left: 10px;
  margin-right: 10px;}
.p {
  font-size: 0.8em
}
</style>
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment=NA, warning=FALSE, message=FALSE)
suppressMessages(library(readr))
suppressMessages(library(dplyr))
suppressMessages(library(seminr))
suppressMessages(library(matrixpls))
suppressMessages(library(semPLS))
suppressMessages(library(pwr))
suppressMessages(library(expss))
suppressMessages(library(openxlsx))
suppressMessages(library(lavaan))

#suppressMessages(agencias <- read_spss("~/R/r-data/00.pls-seminr/data/agencias_dc.sav"))
data <- read_csv("~/R/r-projects/00.publicaciones/data.art2vallejo/data.h.a.csv")
options(width=9999)
```

# Tablas muestra

```{r}
#wb = createWorkbook()
#sh = addWorksheet(wb, "Tablas")
#tab1 <- agencias %>%
#     tab_cells(mrset(P1_1,P1_2), mrset_f(P2_),mrset_f(P3_)) %>% 
#     tab_stat_cases(label='casos') %>%
#     tab_stat_cpct(label='% casos') %>% 
#     tab_pivot(stat_position='inside_columns')
#as.datatable_widget(tab1)
#xl_write(tab1, wb, sh)
#tab2 <- agencias %>%
#    tab_cols(total()) %>% 
#     tab_cells(P5) %>%
#     tab_stat_fun(Mean = w_mean, "Sd" = w_sd) %>% 
#     tab_weight(1) %>% 
#     tab_cells(P6*10) %>%
#     tab_stat_fun(Mean = w_mean, "Sd" = w_sd) %>% 
#     tab_pivot()
#as.datatable_widget(tab2)
#xl_write(tab2, wb, sh, col=6)
#saveWorkbook(wb, "~/R/r-data/00.pls-seminr/art2-vallejo/tablas.xlsx", overwrite = TRUE)
```

# Modelización


```{r include=FALSE, warning=FALSE, message=FALSE}
df <- data[,1:20]
#======================================
# Create mesaurment model
#======================================
simple_mm <- constructs(
     composite("VCC", multi_items("VCC", c(1:6))),
     composite("TRUST", multi_items("TRUST", 1:3)),
     composite("COMMIT", multi_items("COMMIT", 1:4)),
     composite("SOCSAT", multi_items("SOCSAT",1:3)),
     higher_composite("RQ", dimensions = c("TRUST","COMMIT", "SOCSAT"), method = two_stage, weights=mode_A),
     composite("ECOSAT", multi_items("ECOSAT", 1:3)))
#======================================
# Create structural model
#======================================
simple_sm <- relationships(
     paths(from = c("VCC"), to = c("RQ")),
     paths(from = c("RQ"), to = c("ECOSAT")))
# Estimate the model
simple_model <- estimate_pls(data = df,
                                      measurement_model = simple_mm,
                                      structural_model  = simple_sm,
                                      inner_weights = path_weighting,
                                      missing = mean_replacement,
                                      missing_value = NA)
```

El modelo de medida es el siguiente:

```{r fig.cap='Modelo de medida', fig.width=8, fig.height=4.5}
plot(simple_mm)
```

El modelo estructural es el siguiente:

```{r fig.cap='Modelo estructural', fig.width=8, fig.height=4.5}
# Dibujamos el modelo estructural
plot(simple_sm)
```

## Análisis de la fiabilidad

Para el modelo de medida se han considerado composites, mode A (reflectivos???). De este modo, el primer paso debe ser observar el resumen de los indicadores de fiabilidad, consistencia interna y validez.

El resultado del análisis muestra todas las escalas que apoyan las variables latentes tienen un *Cronbach's alpha* mayor que 0.7, completado por una fiabilidad del compuesto *rhoC* también por encima de 0.7. para valores superiores a 0.9[^1].

[^1]: En <https://forum.smartpls.com/viewtopic.php?f=5&t=3805> hay una "discusión en torno al "greater than 0.9" de Primer PLS ... de Hair; lo solventa un investigador / desarrollador de SmartPLS: <https://www.researchgate.net/profile/Jan_Michael_Becker>

```{r fig.cap='Tabla Resumen', fig.width=16, fig.height=9}
# Summarize the model results
summary_simple <- summary(simple_model)
summary_simple$reliability
```

## Validez convergente

### AVE

Del mismo modo, para evaluar la *validez convergente* o grado con el que una medida correlaciona positivamente con medidas alternativas del mismo constructo, usamos el coeficiente *AVE (average variance extracted)* que también cumple con la expectativa de estar por encima de 0.5.

```{r}
summary_simple$reliability
```

Los indicadores son mostrados de forma conjunta en el siguiente gráfico.

```{r fig.cap='Tabla de fiabilidad', fig.width=16, fig.height=9}
plot(summary_simple$reliability)
```

### Análisis de las cargas

Por otro lado, es importante analizar también las cargas o *loadings*, indicadores de la fiabilidad del indicador en el constructo, y que deberían ser mayores de 0.7 para retener el indicador; para aquellas que están entre 0.4 y 0.7 debe ser analizado el comportamiento del constructo ante una eliminación del indicador con carga baja[^2].

[^2]: En nuestro caso al proceder con la eliminación de aquellas cargas menores de 0.7 no mejoraba significativamente el modelo

```{r}
summary_simple$loadings
#as.data.frame(rowSums(round(summary_simple$loadings,3)))
```

## Validez discriminante

### Cross-loadings

Para el análisis de la validez discriminante o capacidad de un constructo de ser realmente distinto a otros, utilizamos las denominadas *cross-loadings*, que miden esa capacidad del constructo. En la tabla adjunta se puede observar en cada indicador carga de forma superior en su variable latente, siendo el resto de cargas de menor intensidad.

```{r}
summary_simple$validity$cross_loadings
```

### Fornell-Larcker

El criterio de *Fornell-Larcker*, compara la raíz cuadrado del *AVE* con la correlación de las variables latentes. La raíz cuadrada del AVE de cada constructo, debería ser más grande que la más alta correlación con cualquier otro constructo. Se puede observar en la tabla siguiente que el valor en la diagonal principal, es mayor que el resto de valores en la parte inferior de la matriz.

```{r}
summary_simple$validity$fl_criteria
```

### HTMT

Por último el *HTMT* es un ratio que si es mayor que 0.90 indica una pérdida de validez discriminante.

```{r}
summary_simple$validity$htmt
```

## Análisis del modelo estructural

Una vez analizados los constructos desde el punto de vista de su composición, debemos analizar el modelo estructural en su conjunto. Partiendo de que el objetivo del PLS es la maximización de la varianza explicada, las medidas más importantes son la fiabilidad, la validez convergente y la validez discriminante del conjunto del modelo.

-   R<sup>2</sup>, coeficiente de determinación y/o % de varianza explicada
-   f<sup>2</sup> y q<sup>2</sup> efecto tamaño
-   Q<sup>2</sup>, relevancia predictiva

### Paths

```{r}
summary_simple$paths
```

### R<sup>2</sup>

Buscar *R<sup>2</sup>* mayores de 0.7, aunque valores alrededor de 0.25 sean aceptados según ámbitos; (sustancial mayor que 0.75, moderado alrededor de 0.5 y débil, 0.25). Usar R<sup>2</sup><sub>adj</sub> para comparar modelos con diferente número de constructos y/u observaciones.

```{r}
simple_model$rSquared
```

### f<sup>2</sup> - effect sizes

El *f<sup>2</sup>* permite evaluar la contribución de cada constructo exógeno a la R<sup>2</sup> de un constructo endógeno. Los valores de 0.02, 0.15 y 0.35 indican un efecto pequeño, mediano o grande sobre el constructo endógeno.

```{r}
summary_simple$fSquare
```

### Efectos

#### Totales

```{r}
summary_simple$total_effects
```

#### Indirectos

```{r}
summary_simple$total_indirect_effects
```

# Modelización con bootstrapping

*Bootstrapping* para calcular la significatividad de los paths estimados. Habitualmente se trabaja con un 5% (t \> 1.96) lo que implica significatividad al 95%. Podemos cambiar al 10 o al 1 según ámbito. Usar doble bootstrapping si hay menos de 4 constructos.

```{r}
# Bootstrap the model
boot_model <- bootstrap_model(seminr_model = simple_model,nboot = 5000,seed = 123)
summary_boot <- summary(boot_model)
```

## Structural paths

```{r}
summary_boot$bootstrapped_paths
```

## Bootstrapped loadings

```{r}
summary_boot$bootstrapped_loadings
```

## Bootstrapped HTMT

```{r}
summary_boot$bootstrapped_HTMT
```

## Total effects (paths)

```{r}
summary_boot$bootstrapped_total_paths
```

## Plot model

```{r fig.cap='Modelo con bootstrapping', fig.width=8, fig.height=4.5}
plot(boot_model, theme=seminr_theme_smart())
```

```{r}
# Predicción (seminr)
### Generate the model predictions
#predict_simple_model <- predict_pls(
#  model = simple_model,
#  technique = predict_DA,
#  noFolds = 10,
#  cores=NULL)
##
### Summarize the prediction results
#sum_predict_simple_model <- summary(predict_simple_model)
##
#sum_predict_simple_model
```

# Potencia (pwr)

En nuestro ejemplo tenemos una muestra 524 HOTELES y AGENCIAS, y la regresión más complicada es la del HCO con 3 regresores por lo que v=268-3-1=264.


```{r}

#======================================
# Potencia de las regresiones
#======================================

# N= (tamaño muestral) 
# u = número de variables independientes de la mayor regresión
# v = N -u -1
# f2 = 0.15 (efecto medio)
# sig.level es el nivel de significación, normalmente 0.05

pwr.f2.test(u =3, v = 521 , f2 =0.1 , sig.level = 0.01, power = NULL)

#Si quisiéramos saber la muestra necesaria para alcanzar una potencia del 80%

pwr.f2.test(u =3, v = NULL , f2 =0.1 , sig.level = 0.01, power = 0.80)
```

El resultado indica que nuestro tamaño muestra posee una potencia igual al valor del resultado de *power*, ya que el tamaño muestral máximo para una potencia del 80% sería del valor del resultado del valor de *v* elementos con los parámetros indicados.

# MGA Estimation

Análisis multi-grupo

El análisis multigrupo permite testar si en los grupos de datos predefinidos hay diferencias significativas en las estimaciones de los parámetros específicos de cada grupo (por ejemplo, pesos, cargas y coeficientes path). SmartPLS proporciona resultados para los tres diferentes enfoques en base a los resultados de bootstrapping para cada grupo. Sarstedt et al. (2011) además de Hair et al. (2018) el cual describe en detalle los enfoques de análisis multigrupo. Este método es una prueba de significación no paramétrica para testar la diferencia de resultados específicos de grupo que se basa en los resultados de un proceso de bootstrapping en PLS-SEM. El valor p original (antiguo) de una cola muestra un resultado significativo al nivel del 5% de probabilidad de error, si el valor p es menor que 0,05 o mayor que 0,95 para una cierta diferencia de coeficientes path específicos para cada grupo. El nuevo valor p representa un test de dos colas (si se elige en los ajustes).

Nota: El método PLS-MGA (Henseler et al., 2009), tal como se implementó en SmartPLS, es una extensión del método MGA no paramétrico original de Henseler (tal como se describe, por ejemplo, en Sarstedt et al., 2011).

```{r}
mga <- estimate_pls_mga(simple_model, df$TIPO < 2, nboot=100)
summary(mga)
print.seminr_pls_mga(estimate_pls_mga(simple_model, df$TIPO < 2, nboot=100))
```

Hair, J. F., Sarstedt, M., Ringle, C. M., & Gudergan, S. P. (2018). Advanced Issues in Partial Least Squares Structural Equation Modeling (PLS-SEM), Thousand Oaks, CA: Sage.

Henseler, J., Ringle, C. M. y Sinkovics, R. R. (2009). The Use of Partial Least Squares Path Modeling in International Marketing, Advances in International Marketing, 20: 277-320.

Sarstedt, M., Henseler, J., y Ringle, C. M. (2011). Multi-Group Analysis in Partial Least Squares (PLS) Path Modeling: Alternative Methods and Empirical Results, Advances in International Marketing, 22: 195-218.
