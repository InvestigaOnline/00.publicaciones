---
title: "PLS - Agencias"
subtitle: 'Artículo 2'
author: "Roberto Gil-Saura"
date: "2/4/2021"
output:
  html_document: 
    highlight: tango
    number_sections: yes
    df_print: paged
    toc: true
---

```{=html}
<style type="text/css">
.main-container {
  max-width: 100%;
  margin-left: 10px;
  margin-right: 10px;}
.p {
  font-size: 0.8em
}
</style>
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment=NA)
suppressMessages(library(dplyr))
suppressMessages(library(seminr))
suppressMessages(library(expss))
suppressMessages(library(corrplot))
suppressMessages(library(nortest))
suppressMessages(library(psych))
suppressMessages(library(kableExtra))
suppressMessages(a.data <- read_spss("~/R/r-data/00.pls-seminr/agencias.sav"))
options(width=9999)
```

# Consideraciones sobre la muestra

Recolección de datos a agencias de viaje mediante entrevista personal y presencial. La muestra de `r nrow(a.data)` de conveniencia fue recogida en [ciudades] y los datos más relevantes son [descripción mínima de muestra]. El banco de datos, a partir de las hipótesis teóricas previamente establecidas, permite establecer un modelo de medida y un conjunto de relaciones que conforman un modelo estructural con 6 variables latentes o constructos. La muestra es suficiente pues permite gran margen sobre las reglas de 10 veces más que el mayor número de indicadores sobre constructo y/o también 10 veces mayor que el mayor número de relaciones indicando a una variable latente (). El objetivo de la investigación es claramente exploratorio y predictivo.

```{r include=FALSE, warning=FALSE, message=FALSE, fig.width=16, fig.height=9}
a.df <-select(a.data,
              ID=CUESTIONARIO,
               TRUST1=P8,
               TRUST2=P9,
               TRUST3=P10,
               COMMITMENT1=P11,
               COMMITMENT2=P12,
               COMMITMENT3=P13,
               COMMITMENT4=P14,
               VcC1=P15,
               VcC2=P16,
               VcC3=P17,
               VcC4=P18,
               VcC5=P19,
               VcC6=P20,
               ECOSAT1=P43,
               ECOSAT2=P44,
               ECOSAT3=P45,
               SOCSAT1=P46,
               SOCSAT2=P47,
               SOCSAT3=P48,
               ICT1=P110,
               ICT2=P111,
               ICT3=P112,
               ICT4=P113,
               ICT5=P114
              )
a.simple_mm <- constructs(
     composite("VcC", multi_items("VcC", 1:6)),
     composite("TRUST", multi_items("TRUST", 1:3)),
     composite("COMMITMENT", multi_items("COMMITMENT", 1:4)),
     composite("ECOSAT", multi_items("ECOSAT", 1:3)),
     composite("SOCSAT", multi_items("SOCSAT",1:3)),
     higher_composite("RQ", dimensions = c("TRUST","COMMITMENT","SOCSAT"), method = two_stage, weights = mode_A))

# Create structural model ----
a.simple_sm <- relationships(
     paths(from = c("VcC"), to = c("RQ")),
     paths(from = c("RQ"), to = c("ECOSAT")))
# Estimate the model
simple_model <- estimate_pls(data = a.df,
                                      measurement_model = a.simple_mm,
                                      structural_model  = a.simple_sm,
                                      inner_weights = path_weighting,
                                      missing = mean_replacement,
                                      missing_value = NA)
```

Un análisis descriptivo de los indicadores arroja los siguientes resultados.

```{r fig.cap='Descriptivos de indicadores', fig.width=8, fig.height=4.5, echo=FALSE}
# descripción de los datos
describe(select(a.df, -1))
```

Realizada la prueba de normalidad a los indicadores, observamos que la gran mayoría presenta problemas de normalidad, al tratarse de una escala ordinal. Utilizado el test Lilliefors (Kolmogorov-Smirnov).

```{r fig.width=8, fig.height=4.5, echo=FALSE}
# prueba de normalidad
lillie.test(a.df$TRUST1)
lillie.test(a.df$TRUST2)
lillie.test(a.df$TRUST3)
lillie.test(a.df$COMMITMENT1)
lillie.test(a.df$COMMITMENT2)
lillie.test(a.df$COMMITMENT3)
lillie.test(a.df$COMMITMENT4)
lillie.test(a.df$VcC1)
lillie.test(a.df$VcC2)
lillie.test(a.df$VcC3)
lillie.test(a.df$VcC4)
lillie.test(a.df$VcC5)
lillie.test(a.df$VcC6)
lillie.test(a.df$ECOSAT1)
lillie.test(a.df$ECOSAT2)
lillie.test(a.df$ECOSAT3)
lillie.test(a.df$SOCSAT1)
lillie.test(a.df$SOCSAT2)
lillie.test(a.df$SOCSAT3)
lillie.test(a.df$ICT1)
lillie.test(a.df$ICT2)
lillie.test(a.df$ICT3)
lillie.test(a.df$ICT4)
lillie.test(a.df$ICT5)
```

Las correlaciones de los indicadores en el constructo muestran los siguientes resultados.

```{r, fig.cap='Correlaciones 1', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,2:4),   method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

```{r, fig.cap='Correlaciones 2', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,5:8),   method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

```{r, fig.cap='Correlaciones 3', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,9:13),  method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

```{r, fig.cap='Correlaciones 4', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,15:17), method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

```{r, fig.cap='Correlaciones 5', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,18:20), method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

```{r, fig.cap='Correlaciones 6', fig.width=16, fig.height=9}
# correlaciones
pairs.panels(select(a.df,21:25), method="pearson", show.points=TRUE, ellipses=TRUE, smooth=TRUE, density=TRUE, cor=TRUE, stars=TRUE, scale=TRUE, hist.col="cadetblue")
```

En los gráficos siguientes mostramos el modelo de medida (outer model) y el modelo estructural (inner model), establecidos a partir de las hipótesis lanzadas.

```{r fig.cap='Modelo de medida', warning=FALSE, message=FALSE, fig.width=16, fig.height=9}
plot(a.simple_mm)
```

```{r fig.cap='Modelo estructural',warning=FALSE, message=FALSE, fig.width=16, fig.height=9}
plot(a.simple_sm)
```

# Análisis de la fiabilidad

Para el modelo de medida se han considerado constructos reflectivos. De este modo, el primer paso debe ser observar el resumen de los indicadores de fiabilidad, consistencia interna y validez. 

El resultado del análisis muestra todas las escalas que apoyan las variables latentes tienen un _Cronbach's alpha_ mayor que 0.7, completado por una fiabilidad del compuesto rhoC también por encima de 0.7. para valores superiores a 0.9 ver nota^[En https://forum.smartpls.com/viewtopic.php?f=5&t=3805 hay una "discusión en torno al "greater than 0.9" de Primer PLS ... de Hair; lo solventa un desarrollador de SmartPLS que es investigador: https://www.researchgate.net/profile/Jan_Michael_Becker]. 

```{r fig.cap='Tabla Resumen', fig.width=16, fig.height=9}
# Summarize the model results
summary_simple <- summary(simple_model)
summary_simple$reliability[,1:2]
```
Estos indicadores son mostrados de forma conjunta en el siguiente gráfico.

```{r fig.cap='Tabla de fiabilidad', fig.width=16, fig.height=9}
plot(summary_simple$reliability)
```

# Validez convergente

## AVE

Del mismo modo, para evaluar la *validez convergente* o grado con el que una medida correlaciona positivamente con medidas alternativas del mismo constructo, usamos el coeficiente _AVE (average variance extracted)_ que también cumple con la expectativa de estar por encima de 0.5.

```{r fig.cap='AVE (average variance extracted)'}
as.matrix(summary_simple$reliability[,3])
```

## Loadings

Por otro lado, es importante analizar también las cargas o _loadings_, indicadores de la fiabilidad del indicador en el constructo, y que deberían ser mayores de 0.7 para retener el indicador; para aquellas que están entre 0.4 y 0.7 debe ser analizado el comportamiento del constructo ante una eliminación del indicador con carga baja^[En nuestro caso al proceder con la eliminación de aquellas cargas menores de 0.7 no mejoraba significativamente el modelo].

```{r fig.cap='Loadings'}
summary_simple$loadings
```

# Validez discriminante

## Cross-loadings

Para el análisis de la validez discriminante o capacidad de un constructo de ser realmente distinto a otros, utilizamos las denominadas _cross-loadings_, que miden esa capacidad del constructo. En la tabla adjunta se puede observar en cada indicador carga de forma superior en su variable latente, siendo el resto de cargas de menor intensidad.

```{r fig.cap='Cross-loadings'}
summary_simple$validity$cross_loadings
```

## Fornell-Larcker

El criterio de Fornell-Larcker, compara la raíz cuadrado del _AVE_ con la correlación de las variables latentes. La raíz cuadrada del AVE de cada constructo, debería ser más grande que la más alta correlación con cualquier otro constructo. Se puede observar en la tabla siguiente que el valor en la diagonal principal, es mayor que el resto de valores en la parte inferior de la matriz.

```{r fig.cap='criterio de Fornell-Larcker'}
summary_simple$validity$fl_criteria
```

## HTMT

Por último el HTMT es un ratio que si es mayor que 0.90 indica una pérdida de validez discriminante.

```{r fig.cap='Hetero trait - mono trait ratio'}
summary_simple$validity$htmt
```
# Modelo estructural

Una vez analizados los constructos desde el punto de vista de su composición, debemos analizar el modelo estructural en su conjunto. Partiendo de que el objetivo del PLS es la maximización de la varianza explicada, las medidas más importantes son la fiabilidad, la validez convergente y la validez discriminante del conjunto del modelo.

* R<sup>2</sup>, coeficiente de determinación y/o % de varianza explicada
* f<sup>2</sup> y q<sup>2</sup> efecto tamaño
* Q<sup>2</sup>, relevancia predictiva

## Análisis de la colinealidad

Colinealidad, estudiada con los inner VIF value (inverso de la tolerancia. Todos los valores deben ser <0.20 en tolerancia, lo que implica ser < 5 en VIF. Los valores se dan para cada constructo.

### vif items

```{r fig.cap=''}
summary_simple$validity$vif_items
```

### vif antecedents

```{r fig.cap=''}
summary_simple$vif_antecedents
```

### Paths

```{r fig.cap=''}
summary_simple$paths
```

### R<sup>2</sup>

Buscar R<sup>2</sup> mayores de 0.7, aunque valores alrededor de 0.25 sean aceptados según ámbitos; (sustancial mayor que 0.75, moderado alrededor de 0.5 y débil, 0.25). Usar R<sup>2</sup><sub>adj</sub> para comparar modelos con diferente número de constructos y/u observaciones.

```{r fig.cap=''}
simple_model$rSquared
```

### f<sup>2</sup> - effect sizes

El f<sup>2</sup> permite evaluar la contribución de cada constructo exógeno a la R<sup>2</sup> de un constructo endógeno. Los valores de 0.02, 0.15 y 0.35 indican un efecto pequeño, mediano o grande sobre el constructo endógeno.

```{r fig.cap=''}
summary_simple$fSquare
```

### Q<sup>2</sup>

Mide la relevancia predictiva de los indicadores sobre el constructo endógeno. Se buscan valores mayores que 0 para establecer la relevancia predictiva.

### q<sup>2</sup> 

mide  la contribución de cada constructo exógeno a la creación de Q2. Valores de 0.02, 0.15 y 0.35 indican un efecto pequeño, mediano o grande sobre la relevancia predictiva de la variable latente.

### SRMR (RMS<sub>theta</sub>) 

Mide el _fitting_ del modelo. Valores menores de 0.08 indican un buen ajuste.

### Q2 total effects (relevancia predictiva)

```{r fig.cap=''}
summary_simple$total_effects
```

### total_indirect_effects

```{r fig.cap=''}
summary_simple$total_indirect_effects
```


### it_criteria

```{r fig.cap=''}
summary_simple$it_criteria
```


# Bootstrapping

_Bootstrapping_ para calcular la significatividad de los paths estimados. Habitualmente se trabaja con un 5% (t > 1.96)  lo que implica significatividad al 95%. Podemos cambiar al 10 o al 1 según ámbito. Usar doble _bootstrapping_ si hay menos de 4 constructos.


```{r fig.cap=''}
# Bootstrap the model
boot_model <- bootstrap_model(seminr_model = simple_model,
                                        nboot = 1000,
                                        cores = NULL,
                                        seed = 123)
summary_boot <- summary(boot_model)
```

# Inspect the structural paths

```{r fig.cap=''}
summary_boot$bootstrapped_paths
```

# Inspect bootstrapped weights

```{r fig.cap=''}
summary_boot$bootstrapped_weights
```

# Inspect bootstrapped loadings

```{r fig.cap=''}
summary_boot$bootstrapped_loadings
```

# Inspect bootstrapped HTMT

```{r fig.cap=''}
summary_boot$bootstrapped_HTMT
```

# Inspect the total effects (paths)

```{r fig.cap=''}
kbl(summary_boot$bootstrapped_total_paths) %>%
  kable_material(c("striped","hover", "condensed"))
```

# Plot model

```{r fig.cap='', fig.width=16, fig.height=9}
plot(boot_model, theme=seminr_theme_smart())
```


# Predicción

```{r}
# Generate the model predictions
predict_simple_model <- predict_pls(
  model = simple_model,
  technique = predict_DA,
  noFolds = 10,
  reps = 10)

# Summarize the prediction results
sum_predict_simple_model <- summary(predict_simple_model)

sum_predict_simple_model
```

